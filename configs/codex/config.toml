model_personality = "pragmatic"
[features]
unified_exec = true
shell_snapshot = true
apps = true
steer = true
personality = true

[sandbox_workspace_write]
network_access = true

[model_providers.ollama]
name = "Ollama"
base_url = "https://ollama.com/v1"
env_key = "OLLAMA_API_KEY"

[profiles.ollama]
model = "glm-4.7:cloud"
model_provider = "ollama"

[mcp_servers.context7]
command = "npx"
args = ["-y", "@upstash/context7-mcp"]

[mcp_servers.sequential-thinking]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]

[mcp_servers.qmd]
command = "qmd"
args = ["mcp"]

